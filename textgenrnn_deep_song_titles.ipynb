{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textgenrnn_deep_song_titles",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ea53dde-323b-4374-ca85-6a27fde311f0"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set the textgenrnn model configuration here. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, set `line_delimited` to `True`."
      ]
    },
    {
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': True,\n",
        "    'max_length': 40,\n",
        "    'max_words': 10000,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': False,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True,\n",
        "    'num_epochs': 50,\n",
        "    'gen_epochs': 2,\n",
        "    'batch_size': 64,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.0,\n",
        "    'max_gen_length': 300,\n",
        "    'validation': False,\n",
        "    'is_csv': False\n",
        "}\n",
        "\n",
        "latest_file = 'titles.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After running the next cell, the cell will ask you to upload a file. Upload **any text file** and textgenrnn will start training and generating creative text based on that file!\n",
        "\n",
        "The cell after that will start the training. And thanks to the power of Keras's CuDNN layers, training is super-fast! When the training is done, running the cell after this will automatically download the weights, the vocab, and the config.\n",
        "\n",
        "(N.B. the uploaded file is only stored in the Colaboratory VM and no one else can see it)"
      ]
    },
    {
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "61ab87b3-382d-4b16-90bc-061d80c016be"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "latest_file = sorted(all_files, key=lambda x: -x[1])[0][0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5167b265-e0df-4957-b393-8bca0101e3d6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5167b265-e0df-4957-b393-8bca0101e3d6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving titles2.txt to titles2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4485
        },
        "outputId": "15bdc6f2-4a0b-4650-a4c8-64b0893d8ec7"
      },
      "cell_type": "code",
      "source": [
        "model_name = 'colaboratory'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=latest_file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19,699 texts collected.\n",
            "Training new model w/ 4-layer, 128-cell Bidirectional LSTMs\n",
            "Training on 738,542 character sequences.\n",
            "Epoch 1/50\n",
            "  458/11539 [>.............................] - ETA: 19:32 - loss: 3.5691\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1832/11539 [===>..........................] - ETA: 16:07 - loss: 3.2063"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3123/11539 [=======>......................] - ETA: 13:54 - loss: 2.9861"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4490/11539 [==========>...................] - ETA: 11:33 - loss: 2.8120"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5945/11539 [==============>...............] - ETA: 9:07 - loss: 2.6307"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7319/11539 [==================>...........] - ETA: 6:54 - loss: 2.4767"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8670/11539 [=====================>........] - ETA: 4:42 - loss: 2.3547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9973/11539 [========================>.....] - ETA: 2:34 - loss: 2.2572"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11285/11539 [============================>.] - ETA: 25s - loss: 2.1756"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1143s 99ms/step - loss: 2.1619\n",
            "Epoch 2/50\n",
            "  475/11539 [>.............................] - ETA: 18:45 - loss: 1.4923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1863/11539 [===>..........................] - ETA: 16:13 - loss: 1.4774"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3167/11539 [=======>......................] - ETA: 14:00 - loss: 1.4712"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4482/11539 [==========>...................] - ETA: 11:46 - loss: 1.4635"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5781/11539 [==============>...............] - ETA: 9:35 - loss: 1.4577"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7142/11539 [=================>............] - ETA: 7:19 - loss: 1.4500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8481/11539 [=====================>........] - ETA: 5:05 - loss: 1.4434"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9866/11539 [========================>.....] - ETA: 2:46 - loss: 1.4372"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11201/11539 [============================>.] - ETA: 33s - loss: 1.4330"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1146s 99ms/step - loss: 1.4314\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "Structural Model for Deep Learning for Parallel Problem Evolutional Recognition\n",
            "\n",
            "Semantic Segmentation of Segmentation of Deep Neural Networks\n",
            "\n",
            "Every (feat. Aroma) (Remix)\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Don't Behaving Rees (Olinish Remix)\n",
            "\n",
            "Every Gold (Robbelboe Remix)\n",
            "\n",
            "Flexing To The Study\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Discorinal Nyntative Diebbased Contexturations\n",
            "\n",
            "Embedding feat. Ceyta Readm\n",
            "\n",
            "Away Erg Inferences and Clusted to Ult C Thaces\n",
            "\n",
            "Epoch 3/50\n",
            "   98/11539 [..............................] - ETA: 21:09 - loss: 1.3453"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1456/11539 [==>...........................] - ETA: 17:21 - loss: 1.3519"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 2762/11539 [======>.......................] - ETA: 14:52 - loss: 1.3510"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4105/11539 [=========>....................] - ETA: 12:29 - loss: 1.3504"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5541/11539 [=============>................] - ETA: 9:58 - loss: 1.3470"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6982/11539 [=================>............] - ETA: 7:32 - loss: 1.3464"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8387/11539 [====================>.........] - ETA: 5:11 - loss: 1.3470"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9995/11539 [========================>.....] - ETA: 2:32 - loss: 1.3462"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11396/11539 [============================>.] - ETA: 14s - loss: 1.3453"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1135s 98ms/step - loss: 1.3456\n",
            "Epoch 4/50\n",
            "  530/11539 [>.............................] - ETA: 18:15 - loss: 1.2974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1924/11539 [====>.........................] - ETA: 15:38 - loss: 1.3036"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3249/11539 [=======>......................] - ETA: 13:30 - loss: 1.3078"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4658/11539 [===========>..................] - ETA: 11:11 - loss: 1.3079"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6021/11539 [==============>...............] - ETA: 8:57 - loss: 1.3077"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7716/11539 [===================>..........] - ETA: 6:12 - loss: 1.3106"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9080/11539 [======================>.......] - ETA: 3:59 - loss: 1.3117"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10418/11539 [==========================>...] - ETA: 1:49 - loss: 1.3121"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1124s 97ms/step - loss: 1.3124\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "A Comparison of Convolutional Networks for Semantic Segmentation\n",
            "\n",
            "Projective Factorization for Active Learning in Sequential Autoencoders\n",
            "\n",
            "A Deep Learning for Prediction Strategies\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "On the Prediction of Structured Means Recognition\n",
            "\n",
            "Boy (feat. Stron The Remix)\n",
            "\n",
            "What in Minimization from Wean Selective Supervisions of Deep Learning for Image Classification\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Wick Os Critich (Backs Reduco) (feat. Stilom Dre)\n",
            "\n",
            "Heolding feat. Noisy Worlds (Biey Pregial)\n",
            "\n",
            "Bim Deep Learning Mixture Informations of Code-Codament Learning thos Genergal Accurrestage Matche Strateg Visual PuApposteles: Algef Boss and the Improving Recovery from the Empirictor Attention Recognition\n",
            "\n",
            "Epoch 5/50\n",
            "   12/11539 [..............................] - ETA: 24:40 - loss: 1.2639"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1281/11539 [==>...........................] - ETA: 17:35 - loss: 1.2865"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 2642/11539 [=====>........................] - ETA: 15:03 - loss: 1.2851"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3978/11539 [=========>....................] - ETA: 12:37 - loss: 1.2854"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5382/11539 [============>.................] - ETA: 10:13 - loss: 1.2846"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6792/11539 [================>.............] - ETA: 7:50 - loss: 1.2876"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8258/11539 [====================>.........] - ETA: 5:24 - loss: 1.2898"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9796/11539 [========================>.....] - ETA: 2:51 - loss: 1.2897"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11147/11539 [===========================>..] - ETA: 38s - loss: 1.2911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1137s 98ms/step - loss: 1.2916\n",
            "Epoch 6/50\n",
            "  410/11539 [>.............................] - ETA: 18:36 - loss: 1.2473"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1842/11539 [===>..........................] - ETA: 15:52 - loss: 1.2628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3158/11539 [=======>......................] - ETA: 13:40 - loss: 1.2709"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4475/11539 [==========>...................] - ETA: 11:31 - loss: 1.2734"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5816/11539 [==============>...............] - ETA: 9:20 - loss: 1.2732"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7206/11539 [=================>............] - ETA: 7:03 - loss: 1.2749"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8574/11539 [=====================>........] - ETA: 4:49 - loss: 1.2761"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9928/11539 [========================>.....] - ETA: 2:38 - loss: 1.2762"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11246/11539 [============================>.] - ETA: 28s - loss: 1.2774"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1138s 99ms/step - loss: 1.2779\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "All I Fine (Prod. By Cover Cover)\n",
            "\n",
            "Something (feat. Angel Marian)\n",
            "\n",
            "Semantic Segmentation of Sparse Coding with Convolutional Neural Networks\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Tracklet Self-Semi-Summarization Learning with Structured Machine Learning\n",
            "\n",
            "Real-time Probjection with Conversence Feature Selection for Deep Neural Networks with Graphical Discoupled Spatial Recognition\n",
            "\n",
            "Scale Segmentation on Models and Recognition\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Joe Canones amo The Tree\n",
            "\n",
            "I Feat. Kellare\n",
            "\n",
            "I'man Jestinal Reconstructional Learning with Challenge\n",
            "\n",
            "Epoch 7/50\n",
            "   87/11539 [..............................] - ETA: 21:48 - loss: 1.2214"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1424/11539 [==>...........................] - ETA: 17:35 - loss: 1.2518"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 2712/11539 [======>.......................] - ETA: 15:10 - loss: 1.2544"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4019/11539 [=========>....................] - ETA: 12:47 - loss: 1.2559"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5300/11539 [============>.................] - ETA: 10:33 - loss: 1.2602"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6632/11539 [================>.............] - ETA: 8:16 - loss: 1.2622"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7932/11539 [===================>..........] - ETA: 6:04 - loss: 1.2649"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9277/11539 [=======================>......] - ETA: 3:47 - loss: 1.2676"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10587/11539 [==========================>...] - ETA: 1:35 - loss: 1.2681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1160s 101ms/step - loss: 1.2697\n",
            "Epoch 8/50\n",
            "  156/11539 [..............................] - ETA: 19:58 - loss: 1.2552"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1521/11539 [==>...........................] - ETA: 16:42 - loss: 1.2587"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 2814/11539 [======>.......................] - ETA: 14:31 - loss: 1.2624"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4093/11539 [=========>....................] - ETA: 12:23 - loss: 1.2628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5432/11539 [=============>................] - ETA: 10:09 - loss: 1.2636"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6950/11539 [=================>............] - ETA: 7:35 - loss: 1.2615"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8335/11539 [====================>.........] - ETA: 5:17 - loss: 1.2630"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9747/11539 [========================>.....] - ETA: 2:57 - loss: 1.2639"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11139/11539 [===========================>..] - ETA: 39s - loss: 1.2649"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1140s 99ms/step - loss: 1.2654\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "A Statistical Analysis of Model Approximation of Models and Automatic Automatic Analysis of Deep Neural Networks\n",
            "\n",
            "Statistic Segmentation of Multi-Convolutional Neural Networks\n",
            "\n",
            "A Computation of Automatic Matrix Factorization and Automatic Analysis of Multiple Contextual Analysis of Automatic Machine Learning Approach to Model Continuous Analysis\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Continuous (Vance Remix)\n",
            "\n",
            "Towards the Love of the Novel of Deep Learning in Medical Networks\n",
            "\n",
            "Captive Named Entity of Deep Neural Networks\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Salk-Inta Reinforcement Learning in Matrix Machines\n",
            "\n",
            "Model Continuous Summarization using a Deep Learning and Entricy mress and wiellish Contextles theory prporamation\n",
            "\n",
            "Cloud\n",
            "\n",
            "Epoch 9/50\n",
            "   64/11539 [..............................] - ETA: 21:09 - loss: 1.2452"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1369/11539 [==>...........................] - ETA: 17:20 - loss: 1.2434"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 2644/11539 [=====>........................] - ETA: 15:03 - loss: 1.2503"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3967/11539 [=========>....................] - ETA: 12:41 - loss: 1.2518"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5281/11539 [============>.................] - ETA: 10:26 - loss: 1.2531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6714/11539 [================>.............] - ETA: 8:00 - loss: 1.2529"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8042/11539 [===================>..........] - ETA: 5:47 - loss: 1.2541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9433/11539 [=======================>......] - ETA: 3:29 - loss: 1.2558"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10761/11539 [==========================>...] - ETA: 1:17 - loss: 1.2572"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1144s 99ms/step - loss: 1.2582\n",
            "Epoch 10/50\n",
            "  249/11539 [..............................] - ETA: 18:58 - loss: 1.2259"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1594/11539 [===>..........................] - ETA: 16:19 - loss: 1.2396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 2982/11539 [======>.......................] - ETA: 14:01 - loss: 1.2379"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4352/11539 [==========>...................] - ETA: 11:46 - loss: 1.2417"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5762/11539 [=============>................] - ETA: 9:27 - loss: 1.2459"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7138/11539 [=================>............] - ETA: 7:12 - loss: 1.2484"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 8489/11539 [=====================>........] - ETA: 4:59 - loss: 1.2504"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9855/11539 [========================>.....] - ETA: 2:45 - loss: 1.2505"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11228/11539 [============================>.] - ETA: 30s - loss: 1.2516"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "11539/11539 [==============================] - 1139s 99ms/step - loss: 1.2517\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "State The With You (The Dave Remix)\n",
            "\n",
            "The Walk (The Noo Boots Remix)\n",
            "\n",
            "The Way We Sound (The White Panda Remix)\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Can It Under (feat. Car Sean In Noun)\n",
            "\n",
            "Fast Recognition of Convolution Neural Networks for Automatic Image Generation\n",
            "\n",
            "Learning to Lost Image Classification by Image Classification in Intelligent Systems\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Twalking Twice? Stranger\n",
            "\n",
            "Whop Perpera (ADM Remix)\n",
            "\n",
            "Quee Reflet : Semi-Supervised A Learning-Model and Hierarchical Variational Architrate Networks for Invementation Selection\n",
            "\n",
            "Epoch 11/50\n",
            "   88/11539 [..............................] - ETA: 22:03 - loss: 1.2320"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  253/11539 [..............................] - ETA: 20:38 - loss: 1.2021"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6a42f702dab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdim_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dim_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     word_level=model_cfg['word_level'])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_from_file\u001b[0;34m(self, file_path, header, delim, new_model, context, is_csv, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             self.train_new_model(\n\u001b[0;32m--> 290\u001b[0;31m                 texts, context_labels=context_labels, **kwargs)\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_new_model\u001b[0;34m(self, texts, context_labels, num_epochs, gen_epochs, batch_size, dropout, validation, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m                             \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                             \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"textgenrnn_weights_saved.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_on_texts\u001b[0;34m(self, texts, context_labels, batch_size, num_epochs, verbose, new_model, gen_epochs, train_size, max_gen_length, validation, dropout, via_new_model, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m                                  \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                                  \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m                                  )\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hu9x1jl7tPpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "185c7900-cd97-49f6-d143-725d550fbf31"
      },
      "cell_type": "code",
      "source": [
        "textgen_2 = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "textgen_2.generate_samples(max_gen_length=1000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "A New Structure for Multi-Label Learning\n",
            "\n",
            "A Survey of Text Detection for Multi-Task Learning\n",
            "\n",
            "A Novel Segmentation of Semantic Segmentation\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Performance Distribution Models for Probabilistic Detection\n",
            "\n",
            "Characteristic (Convolution Recoval Segmentation Extraction\n",
            "\n",
            "Segmentation of Computing Deep Features of Deep Neural Networks for Local Image Segmentation\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Propraltypatche Hey Feed-Norm Network: A Loss Gatertive Learning Label Sentency\n",
            "\n",
            "A Under Reactimbity omorphimillized Social Coverea propagation using Juanty Image and Vision Symmetry with Semi-Supervised Algeriation\n",
            "\n",
            "Unbough\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To recreate the model on your own computer, you can do:\n",
        "\n",
        "```\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=1000)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)\n",
        "```\n",
        "\n",
        "Have fun with your new model! :)\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the virtual machine with the command below:"
      ]
    },
    {
      "metadata": {
        "id": "aCcsCFKUwB21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        },
        "outputId": "b586e580-b470-4938-8533-a473d040a75b"
      },
      "cell_type": "code",
      "source": [
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': False, #True,\n",
        "    'max_length': 10, #40,\n",
        "    'max_words': 10000,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': False,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True, # False,\n",
        "    'num_epochs': 2, # 10,\n",
        "    'gen_epochs': 1,\n",
        "    'batch_size': 64, # 1024,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.1, # 0.0,\n",
        "    'max_gen_length': 50, #300,\n",
        "    'validation': True, # False,\n",
        "    'is_csv': False\n",
        "}\n",
        "\n",
        "latest_file = 'titles2.txt'\n",
        "model_name = 'colaboratory2.1'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=latest_file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18,246 texts collected.\n",
            "Training new model w/ 4-layer, 128-cell LSTMs\n",
            "Training on 658,249 character sequences.\n",
            "Epoch 1/2\n",
            " 1015/10285 [=>............................] - ETA: 5:11 - loss: 3.3439"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4002/10285 [==========>...................] - ETA: 3:21 - loss: 2.2503"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6942/10285 [===================>..........] - ETA: 1:46 - loss: 1.9708"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10285/10285 [==============================] - 356s 35ms/step - loss: 1.8260 - val_loss: 1.4812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "State (Feat. Kanna Alignment Algorithms\n",
            "\n",
            "A Comprehension Algorithm for Convolutional Neur\n",
            "\n",
            "Comprehension of Sparsity of Sensing Algorithms\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Marginals (feat. Cally Furly Coory (feat. Knould\n",
            "\n",
            "Get The Knowledge Learning for Images\n",
            "\n",
            "Learning in Reinforcement Learning for View Algo\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Review pair\n",
            "\n",
            "Fellable (Nien\n",
            "\n",
            "Freeied\n",
            "\n",
            "Epoch 2/2\n",
            "  317/10285 [..............................] - ETA: 5:19 - loss: 1.4357"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 3071/10285 [=======>......................] - ETA: 3:49 - loss: 1.3937"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 6514/10285 [==================>...........] - ETA: 1:59 - loss: 1.3788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9270/10285 [==========================>...] - ETA: 32s - loss: 1.3729"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10285/10285 [==============================] - 356s 35ms/step - loss: 1.3694 - val_loss: 1.3517\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "A Framework for Action Recognition\n",
            "\n",
            "A Real-time Semantic Segmentation\n",
            "\n",
            "A Computational Analysis of the Word Semantic Se\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "All Love\n",
            "\n",
            "Residual Networks\n",
            "\n",
            "Scale Correspondence\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "A Logial Under Learn and Shortup Astagas Bhights\n",
            "\n",
            "Of-the Untret Foreer (Arrashod Remix)\n",
            "\n",
            "Use Checkwn On feat. Charish & On Fett Glusto\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YVyvDxCG9nBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        },
        "outputId": "05751111-f16a-4c06-ca08-ec3cef50b560"
      },
      "cell_type": "code",
      "source": [
        "textgen_3 = textgenrnn(weights_path='colaboratory2.1_weights.hdf5',\n",
        "                       vocab_path='colaboratory2.1_vocab.json',\n",
        "                       config_path='colaboratory2.1_config.json')\n",
        "textgen_3.generate_samples(max_gen_length=75, temperatures=[0.5, 0.9], n=20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Stranger (Neast Remix)\n",
            "\n",
            "Universal Large-scale Classification of the Video Cascade (feat. Arby Rem\n",
            "\n",
            "Learning Backgraph Combining Deep Networks\n",
            "\n",
            "A compression Remix)\n",
            "\n",
            "Change (feat. Sam Make (Radio Edit)\n",
            "\n",
            "Discovery for neural networks for Accurate Images of the Starf (Brake Rem\n",
            "\n",
            "Neural Networks for Compression\n",
            "\n",
            "Computational Structured Object Detection in Approximation for Images and\n",
            "\n",
            "State Improves Complex Framework for Image Segmentation\n",
            "\n",
            "Star-Body and Real-time Categorial Bays Machine Tracking\n",
            "\n",
            "Convolutional Neural Networks for Recognition\n",
            "\n",
            "A Neural Networks\n",
            "\n",
            "A Domain Adaptation\n",
            "\n",
            "Shadone Remix)\n",
            "\n",
            "Computational Language Model for Image Restoration from a Character based\n",
            "\n",
            "Close (feat. Vick Remix)\n",
            "\n",
            "Multi-task Compression of Computational Dialogue feat. Dence That Improve\n",
            "\n",
            "Gold To The Way (Young Hers\n",
            "\n",
            "Love Me Down (Manis Edit)\n",
            "\n",
            "Learning Image Segmentation and Open Segmentation\n",
            "\n",
            "####################\n",
            "Temperature: 0.9\n",
            "####################\n",
            "Residual Supervised ensembles via Like Complained stochastic Preopt Segme\n",
            "\n",
            "Millar Kid\n",
            "\n",
            "Cnazes of Strategiation of An Exploration\n",
            "\n",
            "Instance Generalization\n",
            "\n",
            "Like You Way To (Original Learning from a Hadcer convex framework for Boi\n",
            "\n",
            "Neural Machine\n",
            "\n",
            "Rumed Appearance Embedding Data-Algorithms for Cost\n",
            "\n",
            "A Deep Action Recognition\n",
            "\n",
            "Accurac Recognition: Models\n",
            "\n",
            "The Dimators\n",
            "\n",
            "Day\n",
            "\n",
            "Learning Tracking\n",
            "\n",
            "Fard Machine Translation)\n",
            "\n",
            "Winder\n",
            "\n",
            "Am Net: Deep Learning in Vikeo Superpremenal Lifel\n",
            "\n",
            "Efficient Multi-view Generation\n",
            "\n",
            "Love Me Craw (Ra Likea Remix)\n",
            "\n",
            "I Caze Alber (Samoh Remix)\n",
            "\n",
            "Es Images Using Cning approach to Digraphs from Improvement of Computatio\n",
            "\n",
            "Boinda (Pair Srakes\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWt__FLr-l18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        },
        "outputId": "26b91536-197e-4e2f-f773-1acc2870a428"
      },
      "cell_type": "code",
      "source": [
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': False, #True,\n",
        "    'max_length': 5, #40,\n",
        "    'max_words': 10000,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': False,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True, # False,\n",
        "    'num_epochs': 2, # 10,\n",
        "    'gen_epochs': 1,\n",
        "    'batch_size': 64, # 1024,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.1, # 0.0,\n",
        "    'max_gen_length': 50, #300,\n",
        "    'validation': True, # False,\n",
        "    'is_csv': False\n",
        "}\n",
        "\n",
        "latest_file = 'titles2.txt'\n",
        "model_name = 'colaboratory2.2'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=latest_file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18,246 texts collected.\n",
            "Training new model w/ 4-layer, 128-cell LSTMs\n",
            "Training on 658,024 character sequences.\n",
            "Epoch 1/2\n",
            " 1261/10281 [==>...........................] - ETA: 3:59 - loss: 2.3285"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 5795/10281 [===============>..............] - ETA: 1:53 - loss: 1.8197"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 9502/10281 [==========================>...] - ETA: 19s - loss: 1.7185"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10281/10281 [==============================] - 285s 28ms/step - loss: 1.7049 - val_loss: 1.5304\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "Deep Learning and Face Recurrent Neural Networks\n",
            "\n",
            "Convolution for Image Classifier for Complete Re\n",
            "\n",
            "Complexity of Fast Deep Recognition Approach for\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Strategies\n",
            "\n",
            "Stranger-Self-Aware Language Process (Ratio Recu\n",
            "\n",
            "White Pise Read Exploration and Selection for De\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Overantified using Text Analysis Using and For M\n",
            "\n",
            "Space Camera & Anomaly)\n",
            "\n",
            "HomographicalNs\n",
            "\n",
            "Epoch 2/2\n",
            "  245/10281 [..............................] - ETA: 4:14 - loss: 1.4308"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 4187/10281 [===========>..................] - ETA: 2:30 - loss: 1.4154"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 7903/10281 [======================>.......] - ETA: 58s - loss: 1.4040"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10281/10281 [==============================] - 285s 28ms/step - loss: 1.4008 - val_loss: 1.3970\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "Stranger Remix)\n",
            "\n",
            "Deep Learning for Active Adversarial Networks\n",
            "\n",
            "Deep Learning the Remix)\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "An Efficient Convolutional Neural Neural Generat\n",
            "\n",
            "Regularization for Active Adversation for Statis\n",
            "\n",
            "Learning for Models and Semantic Proposals in Le\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Deep Classifilated Multimodal Systems in Deep De\n",
            "\n",
            "Tray-loss and UnAnlonetun Cldassistent-Video Fas\n",
            "\n",
            "Sawmais Deep Footched Multi& Lic Representation\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sYDgl8fWCJyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        },
        "outputId": "12d822f1-9044-4e22-f36d-07710449c800"
      },
      "cell_type": "code",
      "source": [
        "textgen_3 = textgenrnn(weights_path='colaboratory2.2_weights.hdf5',\n",
        "                       vocab_path='colaboratory2.2_vocab.json',\n",
        "                       config_path='colaboratory2.2_config.json')\n",
        "textgen_3.generate_samples(max_gen_length=75, temperatures=[0.5, 0.8], n=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "Exploring Deep Learning for Paradise Deep Learning\n",
            "\n",
            "Real-Time (feat. Elevation\n",
            "\n",
            "Gold (James Remix)\n",
            "\n",
            "An Analysis of Deep Convolutional Machine Learning\n",
            "\n",
            "Correction in Remix)\n",
            "\n",
            "A Survey\n",
            "\n",
            "Closer (Carmod for Semantics for Video Classification in Social Style Sta\n",
            "\n",
            "Interpretable Remix)\n",
            "\n",
            "Exploring in Prive (Oliver Remix)\n",
            "\n",
            "Deep Convolutional Networks\n",
            "\n",
            "Don't Want (Louis Remix)\n",
            "\n",
            "Stay Water & Get Me (Night Paint for Video Way (feat. Dan Out (feat. Jo R\n",
            "\n",
            "A Subspaces\n",
            "\n",
            "Walk (Saving Relation with Stay Approach to Segmentation and Accelerate C\n",
            "\n",
            "Sun Method (feat. Jush Plan (Alex Remix)\n",
            "\n",
            "On the Remix)\n",
            "\n",
            "Predictive Deep Learning of the Wild\n",
            "\n",
            "Gold To Shot High- Adaptive Adversarial Networks\n",
            "\n",
            "Somether Search by Big Search for Models for Text Data\n",
            "\n",
            "Semi-supervised Action Matrix Fields Remix)\n",
            "\n",
            "####################\n",
            "Temperature: 0.8\n",
            "####################\n",
            "Something Optimization for Remix)\n",
            "\n",
            "Hangs\n",
            "\n",
            "No On Me\n",
            "\n",
            "Shadro Mix)\n",
            "\n",
            "Come Grounded Tere Measurement Detectional Neural Networks\n",
            "\n",
            "Generative Mining for Video Policy in Biomas R. Laving Word Vectors Turk\n",
            "\n",
            "Automatic Samples for sea Remix)\n",
            "\n",
            "Silver (Sving Recognitive Network prooft Remix)\n",
            "\n",
            "Joint Perflow Transfer from A MultivieAtion\n",
            "\n",
            "Living from Transfer enging for Hierarchy from Intractive Sea\n",
            "\n",
            "Transfer Learning Deep Learning the Real This Is Way Sensing Deep Stereo \n",
            "\n",
            "In Love (feat. Love (Jolar Sammula and and Representation using Mix)\n",
            "\n",
            "Hiller\n",
            "\n",
            "Points\n",
            "\n",
            "A Reverse Renderstanding Aware Remix)\n",
            "\n",
            "Scale recognition\n",
            "\n",
            "Better Even Editioning on My Diverse\n",
            "\n",
            "Motion Using a Single Images\n",
            "\n",
            "Sunres the Spition\n",
            "\n",
            "Straron\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-LLLKF_uSzG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYuI4dfuTjyJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lost track of what model the below samples came from..."
      ]
    },
    {
      "metadata": {
        "id": "kEB_BXZMwaaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        },
        "outputId": "90c6d188-fd8f-483e-cd51-47370f45a1e6"
      },
      "cell_type": "code",
      "source": [
        "textgen_3 = textgenrnn(weights_path='colaboratory2_weights.hdf5',\n",
        "                       vocab_path='colaboratory2_vocab.json',\n",
        "                       config_path='colaboratory2_config.json')\n",
        "textgen_3.generate_samples(max_gen_length=50, temperatures=[0.2, 1.0], n=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "Survey (Lour Remix)\n",
            "\n",
            "Stay (The Knocks Remix)\n",
            "\n",
            "Survey (Brown Remix)\n",
            "\n",
            "Deep Learning for Action Recognition of Semantic\n",
            "\n",
            "Stay (The Knocks Remix)\n",
            "\n",
            "Complex Remix)\n",
            "\n",
            "State Me (Love White A Me (feat. Challenge Remix\n",
            "\n",
            "Learning Theory for Semantic Segmentation with A\n",
            "\n",
            "Deep Learning for Action Recognition with Convol\n",
            "\n",
            "A Complexity with Convolutional Neural Networks \n",
            "\n",
            "Deep Learning for Deep Learning for Convolutiona\n",
            "\n",
            "Deep Learning for Semantic Segmentation of Deep \n",
            "\n",
            "Semantic Segmentation on Semantic Approach to Se\n",
            "\n",
            "Learning Theory (Live Self Model for Semantic Se\n",
            "\n",
            "Complex Convolutional Neural Networks for Semant\n",
            "\n",
            "State The Complexity of Deep Learning for Semant\n",
            "\n",
            "Deep Learning for Active Segmentation of Deep Le\n",
            "\n",
            "Semantic Segmentation of Convolutional Neural Ne\n",
            "\n",
            "The Complexity and Active Segmentation of Multi-\n",
            "\n",
            "The Wild The Word (Star Remix)\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "RAC in Sem(Geo I: Breast Tolking\n",
            "\n",
            "'Coin In You\n",
            "\n",
            "Reinforcement intrassics with Lifoul understandi\n",
            "\n",
            "Good\n",
            "\n",
            "Withn'A (Louis Loop (The Hands (Stay Remix)\n",
            "\n",
            "Sioning Poly Provleba Detection using Artifomi R\n",
            "\n",
            "I Love Down Out Lokel Genre Detection Using Low-\n",
            "\n",
            "Semantic Algorithms and Non-context Use vector T\n",
            "\n",
            "Ihplos\n",
            "\n",
            "Proponing the ConRicting and Adversarialnedin (T\n",
            "\n",
            "Gated To\n",
            "\n",
            "C-Tomt Summarizing and Adversarial Exploiting Wh\n",
            "\n",
            "ReineQ-Vf Callet Waters (Prod. by Sim Real (Mont\n",
            "\n",
            "Encoding Theord when New Lonstan images Explorat\n",
            "\n",
            "The Walk feat. Suin Brey\n",
            "\n",
            "Gau (MET Knanflours Graph Reconstruction and the\n",
            "\n",
            "Multi-Sensing Mapping imageCU superer) for Trans\n",
            "\n",
            "Popure-to-Delogence with Manical Distillation On\n",
            "\n",
            "Juicleben Post Robustone Remix)\n",
            "\n",
            "Automating Training Domain Paptogetes Convolutio\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0-ZNLde-M1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        },
        "outputId": "7ae640b3-82ea-4723-9533-3b2718abd3b7"
      },
      "cell_type": "code",
      "source": [
        "textgen_3.generate_samples(max_gen_length=50, temperatures=[0.2, 1.0], n=20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "A Convolutional Neural Networks\n",
            "\n",
            "A Survey of Semantic Segmentation of Convolution\n",
            "\n",
            "Stay (The Chainsmokers Remix)\n",
            "\n",
            "Learning to Segmentation of Semantic Segmentatio\n",
            "\n",
            "A Fast and Convolutional Neural Networks\n",
            "\n",
            "Multi-Scale Sentence Recognition using Convoluti\n",
            "\n",
            "Stay (feat. Light Marker (feat. James Bark Remix\n",
            "\n",
            "A Deep Learning for Convolutional Neural Network\n",
            "\n",
            "An Embeddings for Convolutional Neural Networks\n",
            "\n",
            "Learning to Segmentation for Semantic Segmentati\n",
            "\n",
            "Multi-Scale Probabilistic Pose Estimation for Se\n",
            "\n",
            "Learning System for Semantic Segmentation of Gen\n",
            "\n",
            "Stay (The Chainsmokers Remix)\n",
            "\n",
            "A Simple Convolutional Neural Networks\n",
            "\n",
            "A Survey of Deep Learning for Structured Languag\n",
            "\n",
            "Stay (feat. Jessin The Deep Learning for Semanti\n",
            "\n",
            "Learning to Segmentation for Transfer Learning f\n",
            "\n",
            "A Composition for Semantic Segmentation of Seman\n",
            "\n",
            "Semantic Segmentation of Marked Descriptors for \n",
            "\n",
            "Fast and Convolutional Neural Networks\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "Language Understanding Approximations and Spinal\n",
            "\n",
            "A Problems of Gents\n",
            "\n",
            "Aspect-based the Realistic Sequence System Deco)\n",
            "\n",
            "It's Bottom Similarity Discovery Based Modeling\n",
            "\n",
            "Big Under\n",
            "\n",
            "Learning analysis using Discriminative between I\n",
            "\n",
            "When We resinae\n",
            "\n",
            "Scan Universal Gaussian Interaction Kroik Remix)\n",
            "\n",
            "Multiobject adaptive on an End-to-end Learning f\n",
            "\n",
            "The Ware Night (Tinom Cover)\n",
            "\n",
            "Impirection Microasion\n",
            "\n",
            "Love Me (Autograf Remix)\n",
            "\n",
            "Task2Quous Dreams\n",
            "\n",
            "Homis-Back-Crowdsourcing Reality Regularizer A M\n",
            "\n",
            "Fuck To Applications\n",
            "\n",
            "Drop Loud\n",
            "\n",
            "DeepSEGK: A Reconstruction\n",
            "\n",
            "Blyp Remix)\n",
            "\n",
            "Hill My Love I Need feat. Remix) (Dut Fix Remix)\n",
            "\n",
            "God's Fall (Hippy agraftic completion\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}